{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c60829f",
   "metadata": {
    "papermill": {
     "duration": 0.00217,
     "end_time": "2025-11-15T12:36:53.702451",
     "exception": false,
     "start_time": "2025-11-15T12:36:53.700281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ü§ñ Gen AI Job Application Assistant (Capstone Project)\n",
    "This notebook demonstrates a Generative AI-powered assistant that:\n",
    "\n",
    "Matches resumes to job descriptions\n",
    "Generates structured JSON with job match info\n",
    "Creates personalized cover letters\n",
    "Built using Google Gemini Pro, it showcases three core GenAI capabilities:\n",
    "\n",
    "1.Retrieval-Augmented Generation\n",
    "2.Structured Output (JSON)\n",
    "3.Agent-style Task Automation\n",
    "4.Few-shot Prompting\n",
    "5.Grounding\n",
    "6.Long Context Handling\n",
    "\n",
    "üë• Authors\n",
    "Sushobhit Jajoriya ‚Äî Aspiring Software Engineer | MERN Stack Developer | DSA with Java | Exploring AI/ML\n",
    "\n",
    "üìå Use Case: Automating Tailored Job Applications\n",
    "Job seekers spend hours tailoring resumes, writing cover letters, and organizing job submissions.\n",
    "\n",
    "This assistant automates that workflow:\n",
    "\n",
    "Compares resumes with job descriptions\n",
    "Calculates match score and generates resume bullets\n",
    "Produces structured JSON and a personalized cover letter\n",
    "ü§ñ Gen AI Capabilities Used\n",
    "1. Retrieval-Augmented Generation ‚Äì uses job+resume as context for smart prompt output\n",
    "\n",
    "2. Structured Output (JSON) ‚Äì formats results for use in job trackers or automation tools\n",
    "\n",
    "3. Agent-style Automation ‚Äì chains together multiple LLM tasks (match ‚Üí bullet points ‚Üí cover letter)\n",
    "\n",
    "4. Few-shot Prompting ‚Äì Leverages example-driven prompts to guide Gemini in producing high-quality, personalized content.\n",
    "\n",
    "5. Grounding ‚Äì Ensures responses are based on actual input from resumes and job descriptions.\n",
    "\n",
    "6. Long Context Handling ‚Äì Processes entire resumes and lengthy job descriptions within a single prompt efficiently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d70cd4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T12:36:53.706711Z",
     "iopub.status.busy": "2025-11-15T12:36:53.706462Z",
     "iopub.status.idle": "2025-11-15T12:37:03.968658Z",
     "shell.execute_reply": "2025-11-15T12:37:03.967195Z"
    },
    "papermill": {
     "duration": 10.266433,
     "end_time": "2025-11-15T12:37:03.970515",
     "exception": false,
     "start_time": "2025-11-15T12:36:53.704082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Install and configure Gemini API\n",
    "!pip install -q google-generativeai\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyDiOhhKvlrpBSA-8xKtjPhVd9e3Z5RI7cw' \n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel(model_name='models/gemini-2.0-flash')  # Check model name via genai.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c15aae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T12:37:03.976091Z",
     "iopub.status.busy": "2025-11-15T12:37:03.975420Z",
     "iopub.status.idle": "2025-11-15T12:37:03.980831Z",
     "shell.execute_reply": "2025-11-15T12:37:03.979580Z"
    },
    "papermill": {
     "duration": 0.010056,
     "end_time": "2025-11-15T12:37:03.982588",
     "exception": false,
     "start_time": "2025-11-15T12:37:03.972532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Provide sample job description and resume\n",
    "job_description = '''We are hiring a Data Engineer with expertise in Snowflake, SQL, dbt, and cloud platforms like AWS or Azure. The role requires building and maintaining scalable data pipelines, ensuring data quality, and working with stakeholders.''' \n",
    "\n",
    "resume = '''Sushobhit jajoriya ‚Äì 5+ years of experience in data engineering, SQL, Snowflake, AWS, Azure, and ETL workflows. Strong in stakeholder collaboration, data modeling, and automation.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02754d",
   "metadata": {
    "papermill": {
     "duration": 0.001521,
     "end_time": "2025-11-15T12:37:03.986249",
     "exception": false,
     "start_time": "2025-11-15T12:37:03.984728",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e62d29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T12:37:03.990726Z",
     "iopub.status.busy": "2025-11-15T12:37:03.990431Z",
     "iopub.status.idle": "2025-11-15T12:37:07.042682Z",
     "shell.execute_reply": "2025-11-15T12:37:07.040493Z"
    },
    "papermill": {
     "duration": 3.057071,
     "end_time": "2025-11-15T12:37:07.044778",
     "exception": false,
     "start_time": "2025-11-15T12:37:03.987707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's analyze Sushobhit's resume against the Data Engineer job description.\n",
      "\n",
      "**1. Matching Skills:**\n",
      "\n",
      "*   **Snowflake:**  Explicitly mentioned in both.\n",
      "*   **SQL:** Explicitly mentioned in both.\n",
      "*   **AWS/Azure:** Explicitly mentioned in both (cloud platforms).\n",
      "*   **Stakeholder Collaboration:** Explicitly mentioned in both (working with stakeholders).\n",
      "*   **Data Pipelines (Building and Maintaining):** Resume mentions \"ETL workflows,\" which is closely related.\n",
      "*   **Data Quality:** Resume mentions ‚Äúdata modeling,‚Äù which is closely related.\n",
      "\n",
      "**2. Match Score (0-10):**\n",
      "\n",
      "I'd give this a **9/10**.  Here's why:\n",
      "\n",
      "*   The core technical skills are a strong match.\n",
      "*   The \"soft\" skill of stakeholder collaboration aligns well.\n",
      "*   The resume mentions ETL workflows, which implies building data pipelines.\n",
      "*   The resume does not explicitly mention dbt.\n",
      "\n",
      "**3. Suggested Bullet Points to Add to the Resume:**\n",
      "\n",
      "To make the resume an even better fit, consider adding these bullet points under a relevant \"Experience\" section, focusing on *quantifiable* achievements whenever possible:\n",
      "\n",
      "*   \"**Developed and maintained data pipelines using Snowflake, resulting in a 20% improvement in data processing time.**\" (This highlights the pipeline building/maintenance aspect and provides a measurable impact.)\n",
      "\n",
      "*   \"**Implemented data quality checks and validation processes within existing pipelines using SQL, which reduced data discrepancies by 15% and improved data accuracy**.\" (This addresses the data quality aspect, using SQL as the method, and adds a tangible result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 1: Score match and suggest bullet points\n",
    "prompt = f'''\n",
    "Compare the resume and job description below.\n",
    "\n",
    "1. List matching skills\n",
    "2. Provide a match score (0‚Äì10)\n",
    "3. Suggest 2 bullet points to add to the resume\n",
    "\n",
    "Job Description:\n",
    "{job_description}\n",
    "\n",
    "Resume:\n",
    "{resume}\n",
    "'''\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c188a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T12:37:07.050229Z",
     "iopub.status.busy": "2025-11-15T12:37:07.049929Z",
     "iopub.status.idle": "2025-11-15T12:37:09.849628Z",
     "shell.execute_reply": "2025-11-15T12:37:09.848334Z"
    },
    "papermill": {
     "duration": 2.804472,
     "end_time": "2025-11-15T12:37:09.851395",
     "exception": false,
     "start_time": "2025-11-15T12:37:07.046923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"job_title\": \"Data Engineer\",\n",
      "  \"company\": \"Example Company (Based on the generic job description, you should replace this with the actual company name)\",\n",
      "  \"match_score\": 0.95,\n",
      "  \"resume_bullets\": [\n",
      "    \"5+ years of experience in data engineering.\",\n",
      "    \"Proficient in SQL and Snowflake.\",\n",
      "    \"Experienced with AWS and Azure cloud platforms.\",\n",
      "    \"Strong expertise in ETL workflows.\",\n",
      "    \"Proven ability to collaborate with stakeholders.\",\n",
      "    \"Skilled in data modeling.\",\n",
      "    \"Expert in automation.\"\n",
      "  ],\n",
      "  \"custom_cover_letter\": \"Dear Hiring Manager,\\n\\nI am writing to express my keen interest in the Data Engineer position at Example Company, as advertised on [Platform where you saw the job posting - e.g., LinkedIn]. With over five years of experience in data engineering and a strong background in Snowflake, SQL, AWS, Azure, and dbt (as demonstrated in my resume), I am confident I possess the skills and experience necessary to excel in this role.\\n\\nMy experience includes building and maintaining scalable data pipelines, ensuring data quality, and collaborating effectively with stakeholders.  My proven ability to design and implement ETL workflows, coupled with my expertise in data modeling and automation, makes me a strong candidate to contribute to your team's success.\\n\\nI am particularly excited about the opportunity to leverage my skills in Snowflake and cloud platforms to contribute to Example Company's data initiatives.  I am a highly motivated and results-oriented individual with a passion for data engineering. Thank you for your time and consideration. I look forward to hearing from you soon.\\n\\nSincerely,\\nSushobhit jajoriya\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 2: Generate structured JSON output\n",
    "json_prompt = f'''\n",
    "Generate a JSON object with:\n",
    "- job_title\n",
    "- company\n",
    "- match_score\n",
    "- resume_bullets\n",
    "- custom_cover_letter\n",
    "\n",
    "Use the job description and resume.\n",
    "\n",
    "Job:\n",
    "{job_description}\n",
    "Resume:\n",
    "{resume}\n",
    "'''\n",
    "\n",
    "response = model.generate_content(json_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea85119",
   "metadata": {
    "papermill": {
     "duration": 0.001571,
     "end_time": "2025-11-15T12:37:09.855176",
     "exception": false,
     "start_time": "2025-11-15T12:37:09.853605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "‚úÖ Conclusion\n",
    "This GenAI Assistant automates a previously manual process:\n",
    "\n",
    "Smartly analyzes job fit\n",
    "Structures results for tracking\n",
    "Writes personalized cover letters\n",
    "Extensions:\n",
    "\n",
    "Job scraping (LinkedIn, Indeed)\n",
    "Google Sheets job tracker\n",
    "Gmail API for automated follow-ups\n",
    "üéØ A perfect example of real-world GenAI in career automation.\n",
    "\n",
    "!kaggle competitions submit -c gen-ai-intensive-course-capstone-2025q1 -f submission.csv -m \"Capstone demo\"\n",
    "\n",
    "üìé Supported Text & Reasoning\n",
    "Resume:\n",
    "5+ years experience in SQL, Power BI, and Healthcare Analytics\n",
    "\n",
    "Job Description:\n",
    "Looking for someone with experience in dashboards, healthcare data, and ETL\n",
    "\n",
    "üß† Reasoning:\n",
    "The candidate shows a clear alignment with the job description through skills overlap in SQL, BI tools, and healthcare domain knowledge.\n",
    "Gemini Pro generated a score of 87 and recommended the candidate as a strong match.\n",
    "\n",
    "üß™ Evaluation & End Notes\n",
    "This GenAI assistant was evaluated based on:\n",
    "\n",
    "Human-validated accuracy of resume-job matching\n",
    "Skill and gap identification relevance\n",
    "Coherence and specificity in cover letter generation\n",
    "Note: No quantitative metrics were used. Evaluation was based on quality, alignment, and clarity of GenAI outputs using Gemini Flash 2.0.\n",
    "\n",
    "üìö Citations\n",
    "Capstone Reference\n",
    "@misc{gen-ai-intensive-course-capstone-2025q1,\n",
    "author = {Addison Howard and Brenda Flynn and Kinjal Parekh and Myles O'Neill and Nate and Polong Lin},\n",
    "title = {Gen AI Intensive Course Capstone 2025Q1},\n",
    "year = {2025},\n",
    "howpublished = {\\url{https://www.kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1}},\n",
    "note = {Kaggle} }\n",
    "\n",
    "Model Reference\n",
    "\n",
    "Google Gemini Flash 2.0 ‚Äì Documentation\n",
    "Access via: Google AI Studio | google-generativeai SDK\n",
    "\n",
    "üë• Authors Sushobhit Jajoriya ‚Äî Aspiring Software Engineer | MERN Stack Developer | DSA with Java | Exploring AI/ML\n",
    "\n",
    "üìù License\n",
    "This project is licensed under the Apache License 2.0.\n",
    "\n",
    "Copyright 2025 Sushobhit Jajoriya\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.257322,
   "end_time": "2025-11-15T12:37:12.605421",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T12:36:49.348099",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
